{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a991255d-b189-43c6-8cc1-3a7be8b90614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import sleep\n",
    "import random\n",
    "import traceback\n",
    "import threading\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598c35f-f4ed-44b2-8281-eec726213467",
   "metadata": {},
   "source": [
    "# GET PROXIES FROM WEBSITE FREE PROXIES LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3fdb861-4f05-4057-aacd-9b76aacf41d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_proxies():\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    soup = bs(requests.get(url).content, 'html.parser')\n",
    "    proxies = []\n",
    "\n",
    "    for row in soup.find(\"table\", class_='table table-striped table-bordered').find_all('tr')[1:]:\n",
    "        tds = row.find_all('td')\n",
    "        try:\n",
    "            ip = tds[0].text.strip()\n",
    "            port = tds[1].text.strip()\n",
    "            proxy = ip + ':' + port\n",
    "            proxies.append(proxy)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6dcf9-d73b-4787-9a5e-3895314c1d71",
   "metadata": {},
   "source": [
    "# CHECK PROXIES IF WORKING AND USE FETCH NEWS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7aeca66-4bed-41bb-9b3a-2306e5bf8673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_proxy(proxy, seen_urls):\n",
    "    counter = 0\n",
    "    try:\n",
    "        url = 'https://httpbin.org/ip'\n",
    "        response = requests.get(url, proxies={'http': proxy, 'https': proxy}, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            news_info, counter = fetch_news('https://www.bbc.co.uk/search?q=lionel+messi&d=TOPICS_GNL&seqId=a61ecac0-ccca-11ee-ba1a-637c905a4107&page=2', proxy, seen_urls, counter)\n",
    "            return news_info\n",
    "    except Exception as e:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db168209-d707-44df-ab86-04e5a52556c9",
   "metadata": {},
   "source": [
    "# FETCH NEWS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1123f2f-b522-4a97-a683-e62aad43c35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_news(link, proxy, seen_urls, counter):\n",
    "    news_info = []\n",
    "    try:\n",
    "        res = requests.get(link, proxies={'http': proxy, 'https': proxy}, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = res.content\n",
    "        soup = bs(webpage, 'html.parser')\n",
    "\n",
    "        for index, link in enumerate(soup.find_all('a', class_='ssrcss-its5xf-PromoLink exn3ah91')):\n",
    "            if counter >= 10:\n",
    "                break\n",
    "            href = link.get('href')\n",
    "            if href not in seen_urls:\n",
    "                seen_urls.add(href)\n",
    "                news_info.append({\n",
    "                    'Link Number': index,\n",
    "                    'Link': href,\n",
    "                    'Proxy IP': proxy,\n",
    "                    \n",
    "                })\n",
    "\n",
    "                try:\n",
    "                    res_inside = requests.get(href, proxies={'http': proxy, 'https': proxy}, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                    webpage_inside = res_inside.content\n",
    "                    soup_inside = bs(webpage_inside, 'html.parser')\n",
    "                    title = soup_inside.title.text.strip()\n",
    "                    print(f'LINK: {index}, HTML: {title}')\n",
    "\n",
    "                    Ip_URL = \"https://ipinfo.io/json\"\n",
    "                    Ip = requests.get(Ip_URL, proxies={'http': proxy, 'https': proxy}, headers={'User-Agent': 'Mozilla/5.0'}).json()\n",
    "                    print(f'IP: {Ip[\"ip\"]}')\n",
    "\n",
    "                    news_info[-1]['Title'] = title\n",
    "                    news_info[-1]['IP'] = Ip[\"ip\"]\n",
    "                    counter += 1\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "    return news_info, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a13e20-0815-4d4b-b0af-2c3e2718af84",
   "metadata": {},
   "source": [
    "# MAIN FUNCTION FOR RUNNING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c59d0ee9-3410-4b77-beca-021197ec4880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "LINK: 0, HTML: Luis Suarez: Uruguay striker joins Inter Miami & reunites with Lionel Messi - BBC Sport\n",
      "LINK: 1, HTML: Lionel Messi: Six of Argentina captain's shirts from 2022 World Cup sell for combined Â£6.1m - BBC Sport\n",
      "LINK: 2, HTML: The Best Fifa Awards 2023: Aitana Bonmati, Erling Haaland and Lionel Messi on Best Fifa player shortlists - BBC Sport\n",
      "LINK: 4, HTML: Lionel Messi: Argentina forward named Time magazine's athlete of the year - BBC Sport\n",
      "LINK: 5, HTML: Lionel Messi: Inter Miami forward is 'gripping' United States, says Guillem Balague - BBC Sport\n",
      "LINK: 6, HTML: Lionel Messi: Inter Miami forward is 'gripping' United States, says Guillem Balague - BBC Sport\n",
      "IP: 20.219.183.188\n",
      "IP: 20.219.180.105\n",
      "IP: 20.204.214.79\n",
      "LINK: 7, HTML: Rodrygo: Brazil forward says he was racially abused on social media after row with Lionel Messi - BBC Sport\n",
      "LINK: 3, HTML: Lionel Messi and Cristiano Ronaldo to meet in friendly as Inter Miami head to Saudi Arabia - BBC Sport\n",
      "IP: 20.219.177.85\n",
      "LINK: 8, HTML: Brazil v Argentina: Lionel Messi tries to intervene as crowd trouble delays kick-off - BBC Sport\n",
      "IP: 20.44.188.17\n",
      "IP: 20.44.189.184\n",
      "IP: 20.44.190.150\n",
      "LINK: 9, HTML: Brazil 0-1 Argentina: Lionel Messi after fans and police clash in stands - BBC Sport\n",
      "_\n",
      "IP: 20.219.183.188\n",
      "IP: 20.219.180.105\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "_\n",
      "Scraping completed. News data saved to news_data.csv.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    proxies = get_proxies()\n",
    "    seen_urls = set()\n",
    "    news_data = []\n",
    "    counter = 0\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(check_proxy, proxies, [seen_urls] * len(proxies)))\n",
    "\n",
    "    for result in results:\n",
    "        for news_info in result:\n",
    "            news_data.append(news_info)\n",
    "\n",
    "    # Write news data to CSV file\n",
    "    with open('news_data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Link Number', 'Link', 'Proxy IP', 'Title', 'IP']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(news_data)\n",
    "\n",
    "    print(\"Scraping completed. News data saved to news_data.csv.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b3a99-96d2-4bba-9e92-634a92ef84a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
